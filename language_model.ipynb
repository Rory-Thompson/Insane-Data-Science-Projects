{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2b1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f77769b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb_data(data_file):\n",
    "    df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "    texts = df['review'].tolist()\n",
    "    labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164229d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(r'C:\\Users\\rory\\Documents\\IMDB_Dataset.csv')\n",
    "texts = df['review'].tolist()\n",
    "labels = [1 if sentiment == \"positive\" else 0 for sentiment in df['sentiment'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "598d677f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'IMDB_Dataset.csv', 'kaggle_data', 'language_model.ipynb', 'My Music', 'My Pictures', 'My Videos', 'tester.ipynb', 'Uno']\n"
     ]
    }
   ],
   "source": [
    "directory = r'C:\\Users\\rory\\Documents'\n",
    "files = os.listdir(directory)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b7800d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce5c38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91dc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976252ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a46b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0640090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "    return \"positive\" if preds.item() == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "052f7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "num_classes = 2\n",
    "max_length = 128\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 2e-5\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba7e98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "345414af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rory\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f00f6a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     accuracy, report \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader, device)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, scheduler, device)\u001b[0m\n\u001b[0;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(outputs, labels)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     12\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train(model, train_dataloader, optimizer, scheduler, device)\n",
    "    accuracy, report = evaluate(model, val_dataloader, device)\n",
    "    print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032f82e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie was great and I really enjoyed the performances of the actors.\n",
      "Predicted sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "test_text = \"this movie was not great\"\n",
    "sentiment = predict_sentiment(test_text, model, tokenizer, device)\n",
    "print(\"The movie was great and I really enjoyed the performances of the actors.\")\n",
    "print(f\"Predicted sentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8a9020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The movie was great and I really enjoyed the performances of the actors.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\"The movie was great and I really enjoyed the performances of the actors.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fe50ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe movie was great and I really enjoyed the performances of the actors.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "model.encode('The movie was great and I really enjoyed the performances of the actors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a759b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.1475975215435028,\n",
       "   'token': 2145,\n",
       "   'token_str': 'still',\n",
       "   'sequence': '[CLS] my penis is still [MASK]. [SEP]'},\n",
       "  {'score': 0.1113625317811966,\n",
       "   'token': 2061,\n",
       "   'token_str': 'so',\n",
       "   'sequence': '[CLS] my penis is so [MASK]. [SEP]'},\n",
       "  {'score': 0.0420222245156765,\n",
       "   'token': 3294,\n",
       "   'token_str': 'completely',\n",
       "   'sequence': '[CLS] my penis is completely [MASK]. [SEP]'},\n",
       "  {'score': 0.03979630023241043,\n",
       "   'token': 2025,\n",
       "   'token_str': 'not',\n",
       "   'sequence': '[CLS] my penis is not [MASK]. [SEP]'},\n",
       "  {'score': 0.036821480840444565,\n",
       "   'token': 2200,\n",
       "   'token_str': 'very',\n",
       "   'sequence': '[CLS] my penis is very [MASK]. [SEP]'}],\n",
       " [{'score': 0.14292874932289124,\n",
       "   'token': 2524,\n",
       "   'token_str': 'hard',\n",
       "   'sequence': '[CLS] my penis is [MASK] hard. [SEP]'},\n",
       "  {'score': 0.07940872013568878,\n",
       "   'token': 14750,\n",
       "   'token_str': 'aching',\n",
       "   'sequence': '[CLS] my penis is [MASK] aching. [SEP]'},\n",
       "  {'score': 0.05975637957453728,\n",
       "   'token': 17061,\n",
       "   'token_str': 'throbbing',\n",
       "   'sequence': '[CLS] my penis is [MASK] throbbing. [SEP]'},\n",
       "  {'score': 0.047738220542669296,\n",
       "   'token': 14908,\n",
       "   'token_str': 'erect',\n",
       "   'sequence': '[CLS] my penis is [MASK] erect. [SEP]'},\n",
       "  {'score': 0.03068513236939907,\n",
       "   'token': 2440,\n",
       "   'token_str': 'full',\n",
       "   'sequence': '[CLS] my penis is [MASK] full. [SEP]'}]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"My penis is [MASK] [MASK] .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "80857a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "text = [\"456\",\"789\",\"I like playing with dinosaurs\"]\n",
    "encoded_input = tokenizer(text, return_tensors='tf',padding=True, truncation=True)\n",
    "output = model(encoded_input)\n",
    "output.last_hidden_state\n",
    "features = output.last_hidden_state\n",
    "features_list = tf.reshape(features, [features.shape[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6b6a155c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c991dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 7, 768), dtype=float32, numpy=\n",
       "array([[[-0.54378474,  0.2409769 , -0.24549067, ...,  0.23936334,\n",
       "          0.44163346,  0.41809237],\n",
       "        [ 0.25412276, -0.09595229, -0.21622771, ..., -0.31149828,\n",
       "          0.15741283, -0.5495563 ],\n",
       "        [ 1.1260716 ,  0.10477532,  0.58316606, ..., -0.58053017,\n",
       "         -0.38747334, -0.6490364 ],\n",
       "        ...,\n",
       "        [-0.20509365, -0.15304819,  0.01746574, ...,  0.11709079,\n",
       "          0.2677412 ,  0.35618937],\n",
       "        [-0.5041675 ,  0.04745362, -0.06152503, ...,  0.22828154,\n",
       "          0.21252683,  0.31339386],\n",
       "        [-0.10899797, -0.11940696,  0.0282459 , ...,  0.1588327 ,\n",
       "          0.1740753 ,  0.307178  ]],\n",
       "\n",
       "       [[-0.5221435 ,  0.298836  , -0.28603116, ...,  0.2141225 ,\n",
       "          0.5667204 ,  0.6360429 ],\n",
       "        [ 1.3777694 , -0.3641031 ,  0.45124036, ...,  0.04624242,\n",
       "          0.4333403 ,  0.48436096],\n",
       "        [ 0.08393332, -0.23064086, -0.03523014, ..., -0.2599762 ,\n",
       "         -0.41654408, -0.08601542],\n",
       "        ...,\n",
       "        [ 0.07075263, -0.01860213, -0.01458628, ...,  0.15979926,\n",
       "          0.31002265,  0.5782106 ],\n",
       "        [-0.5590423 , -0.00589341,  0.05721737, ...,  0.28479493,\n",
       "          0.51416355,  0.4179106 ],\n",
       "        [-0.01730644,  0.00195678,  0.02379877, ...,  0.19867966,\n",
       "          0.17676723,  0.52364796]],\n",
       "\n",
       "       [[ 0.13502796,  0.34185135, -0.11639468, ..., -0.09587885,\n",
       "          0.39477363,  0.431683  ],\n",
       "        [ 0.470231  ,  0.1987087 , -0.5859963 , ...,  0.01025838,\n",
       "          0.68672436,  0.40596643],\n",
       "        [ 0.14468104,  0.5831337 ,  0.8082197 , ...,  0.1856738 ,\n",
       "         -0.12535474,  0.38456258],\n",
       "        ...,\n",
       "        [-0.48871666,  0.26791093,  0.03472325, ..., -0.03924243,\n",
       "         -0.5529581 ,  0.2867112 ],\n",
       "        [-0.2201449 ,  0.32579455, -0.36208597, ...,  0.5906152 ,\n",
       "          0.50349724, -0.02481708],\n",
       "        [ 0.85203356,  0.09822913, -0.1703283 , ...,  0.275561  ,\n",
       "         -0.5636195 , -0.28011084]]], dtype=float32)>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bac5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = output.last_hidden_state\n",
    "features_list = tf.reshape(features, [features.shape[0], -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04930b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 7, 768), dtype=float32, numpy=\n",
       "array([[[-0.54378474,  0.2409769 , -0.24549067, ...,  0.23936334,\n",
       "          0.44163346,  0.41809237],\n",
       "        [ 0.25412276, -0.09595229, -0.21622771, ..., -0.31149828,\n",
       "          0.15741283, -0.5495563 ],\n",
       "        [ 1.1260716 ,  0.10477532,  0.58316606, ..., -0.58053017,\n",
       "         -0.38747334, -0.6490364 ],\n",
       "        ...,\n",
       "        [-0.20509365, -0.15304819,  0.01746574, ...,  0.11709079,\n",
       "          0.2677412 ,  0.35618937],\n",
       "        [-0.5041675 ,  0.04745362, -0.06152503, ...,  0.22828154,\n",
       "          0.21252683,  0.31339386],\n",
       "        [-0.10899797, -0.11940696,  0.0282459 , ...,  0.1588327 ,\n",
       "          0.1740753 ,  0.307178  ]],\n",
       "\n",
       "       [[-0.5221435 ,  0.298836  , -0.28603116, ...,  0.2141225 ,\n",
       "          0.5667204 ,  0.6360429 ],\n",
       "        [ 1.3777694 , -0.3641031 ,  0.45124036, ...,  0.04624242,\n",
       "          0.4333403 ,  0.48436096],\n",
       "        [ 0.08393332, -0.23064086, -0.03523014, ..., -0.2599762 ,\n",
       "         -0.41654408, -0.08601542],\n",
       "        ...,\n",
       "        [ 0.07075263, -0.01860213, -0.01458628, ...,  0.15979926,\n",
       "          0.31002265,  0.5782106 ],\n",
       "        [-0.5590423 , -0.00589341,  0.05721737, ...,  0.28479493,\n",
       "          0.51416355,  0.4179106 ],\n",
       "        [-0.01730644,  0.00195678,  0.02379877, ...,  0.19867966,\n",
       "          0.17676723,  0.52364796]],\n",
       "\n",
       "       [[ 0.13502796,  0.34185135, -0.11639468, ..., -0.09587885,\n",
       "          0.39477363,  0.431683  ],\n",
       "        [ 0.470231  ,  0.1987087 , -0.5859963 , ...,  0.01025838,\n",
       "          0.68672436,  0.40596643],\n",
       "        [ 0.14468104,  0.5831337 ,  0.8082197 , ...,  0.1856738 ,\n",
       "         -0.12535474,  0.38456258],\n",
       "        ...,\n",
       "        [-0.48871666,  0.26791093,  0.03472325, ..., -0.03924243,\n",
       "         -0.5529581 ,  0.2867112 ],\n",
       "        [-0.2201449 ,  0.32579455, -0.36208597, ...,  0.5906152 ,\n",
       "          0.50349724, -0.02481708],\n",
       "        [ 0.85203356,  0.09822913, -0.1703283 , ...,  0.275561  ,\n",
       "         -0.5636195 , -0.28011084]]], dtype=float32)>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e498062d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       "array([[-7.17280507e-01, -1.76421538e-01,  3.32592070e-01,\n",
       "         3.74702960e-01, -4.11120862e-01, -7.74121135e-02,\n",
       "         6.02245152e-01,  1.30732611e-01,  2.29897082e-01,\n",
       "        -9.99700367e-01, -1.33951187e-01,  3.52798700e-01,\n",
       "         9.64773238e-01, -3.39830637e-01,  7.27449417e-01,\n",
       "        -2.94809639e-01, -3.05940136e-02, -4.45753813e-01,\n",
       "         3.95324856e-01, -1.86041817e-01,  3.07913929e-01,\n",
       "         9.29253757e-01,  3.82708579e-01,  1.57621950e-01,\n",
       "         3.30947280e-01,  2.25208014e-01, -5.28438330e-01,\n",
       "         7.90538669e-01,  8.86050940e-01,  5.85440636e-01,\n",
       "        -3.84449661e-01,  1.45747378e-01, -9.77239013e-01,\n",
       "        -1.30338177e-01,  1.71480313e-01, -9.81212378e-01,\n",
       "         7.22568929e-02, -6.06909394e-01,  1.15858190e-01,\n",
       "         8.72076675e-02, -7.51980364e-01,  2.25891143e-01,\n",
       "         9.96358871e-01,  2.07225367e-01, -3.77747007e-02,\n",
       "        -3.50273728e-01, -9.97534692e-01,  1.68136448e-01,\n",
       "        -7.25165486e-01, -2.55129337e-01, -2.02799112e-01,\n",
       "        -3.23750734e-01,  4.04148586e-02,  2.94182152e-01,\n",
       "         2.37602085e-01,  4.47282493e-01, -2.46678844e-01,\n",
       "         1.22523054e-01, -4.65593599e-02, -5.12655139e-01,\n",
       "        -5.22934377e-01,  2.97454506e-01, -2.91098580e-02,\n",
       "        -7.89899468e-01, -1.25266016e-01, -5.95752239e-01,\n",
       "        -6.35399483e-03, -1.62849456e-01,  1.98157698e-01,\n",
       "        -2.79253889e-02,  5.83813906e-01, -1.42035857e-01,\n",
       "         3.11277032e-01, -5.27122676e-01, -3.29776525e-01,\n",
       "         1.57690823e-01, -5.68263113e-01,  9.99968350e-01,\n",
       "        -2.62521774e-01, -9.60807323e-01, -4.60829496e-01,\n",
       "        -3.65245908e-01,  4.24036950e-01,  6.09832168e-01,\n",
       "        -6.22371435e-01, -9.99796391e-01,  2.10900992e-01,\n",
       "        -5.04167303e-02, -9.78028119e-01,  1.79074913e-01,\n",
       "         1.46992370e-01, -8.01270008e-02, -5.87335289e-01,\n",
       "         4.06744868e-01,  8.14830586e-02, -1.17973827e-01,\n",
       "        -2.15504259e-01,  1.52106389e-01, -1.50330216e-01,\n",
       "         2.08658762e-02, -6.39246106e-02, -1.51163682e-01,\n",
       "         2.05507711e-01, -2.51922995e-01,  2.03646436e-01,\n",
       "        -3.16199392e-01, -7.98847601e-02,  3.37281525e-02,\n",
       "        -3.35081458e-01,  5.64455450e-01,  3.49086076e-01,\n",
       "        -2.85905838e-01,  1.67287052e-01, -9.24115956e-01,\n",
       "         5.75334251e-01, -2.47959375e-01, -9.67446089e-01,\n",
       "        -5.51032722e-01, -9.75325286e-01,  5.24769187e-01,\n",
       "         3.46237421e-02, -1.77394282e-02,  8.34509552e-01,\n",
       "         3.87197614e-01,  2.10592821e-01,  4.38279212e-02,\n",
       "         2.83230305e-01, -9.99989688e-01, -5.22048533e-01,\n",
       "        -3.36145580e-01,  3.32956314e-01, -3.67982686e-02,\n",
       "        -9.57449436e-01, -9.31647360e-01,  4.47768331e-01,\n",
       "         9.05729294e-01,  8.18443950e-04,  9.93020892e-01,\n",
       "        -1.37435198e-01,  8.36403012e-01,  2.32488945e-01,\n",
       "        -1.08628348e-01, -3.03875864e-01, -3.38909626e-01,\n",
       "         3.30426753e-01,  1.11843981e-01, -4.15357530e-01,\n",
       "         2.97025830e-01,  8.76006857e-02, -3.84179465e-02,\n",
       "         1.35761738e-01, -2.18378618e-01,  1.46361932e-01,\n",
       "        -8.61774683e-01, -4.08928484e-01,  8.25967133e-01,\n",
       "         3.05642158e-01,  3.33734304e-01,  6.14950716e-01,\n",
       "        -1.77893922e-01, -2.00244173e-01,  6.29838109e-01,\n",
       "         2.30412528e-01,  3.47500890e-01,  1.70813993e-01,\n",
       "         3.16617519e-01, -4.86639708e-01,  3.14176261e-01,\n",
       "        -6.87752128e-01,  1.42973751e-01,  2.39242822e-01,\n",
       "        -2.19845042e-01,  5.23730874e-01, -9.59509194e-01,\n",
       "        -2.92911321e-01,  1.78162724e-01,  9.67971981e-01,\n",
       "         5.15493810e-01,  1.29250050e-01,  6.03402704e-02,\n",
       "        -1.69547945e-01,  3.16474527e-01, -9.03580666e-01,\n",
       "         9.56291616e-01, -3.93762253e-02,  2.42715642e-01,\n",
       "         2.16517344e-01, -3.39324713e-01, -6.97425902e-01,\n",
       "        -5.48107743e-01,  6.56121433e-01, -7.64621049e-02,\n",
       "        -7.26725459e-01, -6.11702795e-04, -4.25811470e-01,\n",
       "        -2.34312147e-01,  2.34443396e-01,  3.91202688e-01,\n",
       "        -2.12389976e-01, -3.37296695e-01,  4.90120016e-02,\n",
       "         7.92872488e-01,  7.97716141e-01,  5.52966237e-01,\n",
       "        -4.10823673e-01,  3.60386819e-01, -7.06270933e-01,\n",
       "        -3.06653619e-01,  3.29822600e-02,  1.16041824e-01,\n",
       "         3.44645977e-02,  9.83049810e-01,  1.74295127e-01,\n",
       "        -1.15730911e-02, -7.82609999e-01, -9.61229563e-01,\n",
       "         4.87541221e-02, -7.72840500e-01, -3.48894931e-02,\n",
       "        -5.84526181e-01,  2.19187170e-01,  6.13204181e-01,\n",
       "        -3.54442418e-01,  2.19192460e-01, -7.83384025e-01,\n",
       "        -5.33302128e-01,  1.87541187e-01, -2.79739648e-01,\n",
       "         2.03670755e-01, -2.61100411e-01,  7.68616676e-01,\n",
       "        -8.58931318e-02, -4.03492481e-01,  2.63258040e-01,\n",
       "         8.19160402e-01,  5.67550480e-01, -6.58160388e-01,\n",
       "         5.57888508e-01, -1.10028610e-01,  7.41989017e-01,\n",
       "        -4.18247432e-01,  9.22243416e-01,  1.48280412e-01,\n",
       "         5.26001394e-01, -8.60494018e-01,  3.58754188e-01,\n",
       "        -6.09829545e-01,  4.39852118e-01, -1.53536588e-01,\n",
       "        -7.82751262e-01, -2.93077528e-01,  5.13689935e-01,\n",
       "         1.31549105e-01,  8.46938908e-01, -4.02378470e-01,\n",
       "         8.98242354e-01, -7.27552712e-01, -9.23037648e-01,\n",
       "        -2.90101588e-01,  7.84845278e-02, -9.76929307e-01,\n",
       "         1.66040301e-01,  1.76694989e-01, -4.60722804e-01,\n",
       "        -3.29674393e-01, -1.77039862e-01, -9.26395833e-01,\n",
       "         6.81948960e-01,  5.71634807e-02,  9.01332378e-01,\n",
       "         2.48196959e-01, -7.96336710e-01, -2.70045787e-01,\n",
       "        -7.74030566e-01, -8.71550441e-02, -4.65748720e-02,\n",
       "         5.79431832e-01, -2.74142236e-01, -8.82252038e-01,\n",
       "         3.92394066e-01,  3.91682833e-01,  2.66079456e-01,\n",
       "         5.03324807e-01,  9.44609046e-01,  9.97256160e-01,\n",
       "         9.54433680e-01,  7.40202427e-01,  5.37740886e-01,\n",
       "        -8.50026786e-01, -2.96549559e-01,  9.99823093e-01,\n",
       "        -3.06059182e-01, -9.99672532e-01, -8.31801176e-01,\n",
       "        -4.46327209e-01,  1.23234883e-01, -9.99987721e-01,\n",
       "        -6.16634414e-02,  4.29178551e-02, -8.20276201e-01,\n",
       "        -1.89346194e-01,  9.54025626e-01,  8.69112074e-01,\n",
       "        -9.99967039e-01,  6.96009576e-01,  8.52942348e-01,\n",
       "        -5.92335403e-01,  1.58358261e-01,  4.88335341e-02,\n",
       "         9.46631789e-01,  1.35403648e-01,  8.63562450e-02,\n",
       "        -4.52134684e-02,  1.89841479e-01,  2.26546451e-02,\n",
       "        -6.01251185e-01,  4.09758925e-01,  3.85876894e-01,\n",
       "         4.83784050e-01,  1.54402629e-01, -4.53995734e-01,\n",
       "        -7.21762061e-01, -7.99056813e-02,  3.48469466e-02,\n",
       "        -2.93399423e-01, -8.82495642e-01, -1.79929495e-01,\n",
       "        -3.75261337e-01,  6.47592902e-01, -6.77463785e-02,\n",
       "         1.37802050e-01, -4.15726930e-01,  1.13946676e-01,\n",
       "        -5.62291205e-01,  6.75718067e-03,  5.57958782e-01,\n",
       "        -8.82067204e-01, -2.76590735e-01, -3.98818344e-01,\n",
       "        -3.76287311e-01,  4.37335759e-01, -8.77369285e-01,\n",
       "         8.90019178e-01, -1.57667518e-01,  6.51907027e-02,\n",
       "         9.99975681e-01,  2.03646094e-01, -5.42720258e-01,\n",
       "         1.71544701e-01,  1.26399785e-01, -6.00468755e-01,\n",
       "         9.99897420e-01,  2.53365308e-01, -9.42006946e-01,\n",
       "        -4.60762501e-01, -2.81336963e-01, -1.88222572e-01,\n",
       "        -2.98319459e-01,  9.94732559e-01, -5.58235273e-02,\n",
       "         2.85952955e-01,  2.62359828e-01,  9.59687471e-01,\n",
       "        -9.78396416e-01,  3.30152035e-01, -7.83557415e-01,\n",
       "        -9.10355449e-01,  8.86058092e-01,  8.45941186e-01,\n",
       "        -7.71441236e-02, -5.32938182e-01,  4.01363410e-02,\n",
       "         2.46771261e-01,  1.81271240e-01, -7.67592132e-01,\n",
       "         4.51484531e-01,  3.14652592e-01, -9.33586434e-02,\n",
       "         8.54632795e-01, -6.52446747e-01, -4.78889525e-01,\n",
       "         2.31057554e-01,  8.23814198e-02,  3.61640483e-01,\n",
       "        -1.75778896e-01,  3.69506687e-01, -2.83039331e-01,\n",
       "        -8.04090034e-03, -2.03191906e-01, -6.23626888e-01,\n",
       "        -8.83408010e-01,  7.36162961e-02,  9.99932468e-01,\n",
       "         1.39679700e-01, -2.13191748e-01,  7.31111467e-02,\n",
       "        -4.03913148e-02, -4.41454321e-01,  1.57580480e-01,\n",
       "         2.64325768e-01, -1.82459652e-01, -5.26212931e-01,\n",
       "        -2.47184083e-01, -6.60726488e-01, -9.65455115e-01,\n",
       "         4.31091338e-01,  1.45736098e-01, -1.68416515e-01,\n",
       "         9.88272786e-01,  2.88135838e-02,  2.04984710e-01,\n",
       "        -1.93084523e-01,  2.37320706e-01, -3.81198563e-02,\n",
       "         4.52564098e-02, -5.68968236e-01,  9.57549751e-01,\n",
       "        -2.49472469e-01,  4.46342885e-01,  3.65198642e-01,\n",
       "         2.42201224e-01, -2.05585942e-01, -4.92257506e-01,\n",
       "        -9.16611105e-02, -8.89907777e-01,  8.90275761e-02,\n",
       "        -8.53421509e-01,  9.10747945e-01, -4.15759027e-01,\n",
       "         2.84645051e-01,  1.27916723e-01, -7.01802671e-02,\n",
       "         9.99963343e-01, -4.63623852e-01,  4.75221604e-01,\n",
       "        -6.24052286e-02,  5.89175880e-01, -7.55314767e-01,\n",
       "        -2.24867195e-01, -2.83272445e-01,  7.47698098e-02,\n",
       "         3.79580200e-01, -1.99394405e-01,  4.94882427e-02,\n",
       "        -9.29530799e-01, -3.07857960e-01, -1.90032676e-01,\n",
       "        -8.25215936e-01, -9.75998521e-01,  3.62422496e-01,\n",
       "         3.46629441e-01,  1.18459001e-01, -3.70528936e-01,\n",
       "        -4.76120442e-01, -4.52563733e-01,  1.13531820e-01,\n",
       "        -2.54662961e-01, -8.63268435e-01,  6.12543106e-01,\n",
       "        -1.90566421e-01,  4.28027242e-01, -2.22193807e-01,\n",
       "         4.59053189e-01, -4.81588781e-01,  8.93250942e-01,\n",
       "         4.94703591e-01,  2.21580356e-01, -4.10242472e-03,\n",
       "        -6.33417606e-01,  6.84712291e-01, -5.95540643e-01,\n",
       "         4.32728618e-01, -8.84382725e-02,  9.99983966e-01,\n",
       "        -4.25936818e-01, -9.88964662e-02,  4.44344997e-01,\n",
       "         1.85227409e-01, -1.42128095e-01,  2.43672714e-01,\n",
       "        -2.59973109e-01,  1.57573745e-01,  6.50054336e-01,\n",
       "         3.87349993e-01, -2.50507057e-01, -2.23670810e-01,\n",
       "         3.14059168e-01, -3.50298792e-01, -5.76040983e-01,\n",
       "         6.16195977e-01,  7.42138997e-02,  1.32708058e-01,\n",
       "         1.88586101e-01,  5.63685000e-02,  9.51558292e-01,\n",
       "        -1.81211308e-01,  4.61669192e-02, -3.16171527e-01,\n",
       "         1.94358956e-02, -1.64362296e-01, -1.14831612e-01,\n",
       "         9.99851346e-01,  2.09083036e-01, -2.42851973e-01,\n",
       "        -9.81243789e-01,  9.93157625e-02, -7.16566145e-01,\n",
       "         9.94063616e-01,  6.40078008e-01, -7.13522434e-01,\n",
       "         2.86043763e-01,  2.15788335e-01, -7.20788985e-02,\n",
       "         4.32772338e-01, -1.91368192e-01, -2.13493362e-01,\n",
       "         8.57082158e-02,  1.56639032e-02,  9.13363755e-01,\n",
       "        -2.21971482e-01, -9.42160070e-01, -4.06493813e-01,\n",
       "         2.23500967e-01, -8.73616934e-01,  8.57182324e-01,\n",
       "        -3.20266068e-01, -5.50778322e-02, -2.15576544e-01,\n",
       "         3.20195168e-01,  2.39710242e-01, -7.44825751e-02,\n",
       "        -9.32996988e-01,  4.36577760e-02, -1.13820732e-02,\n",
       "         9.15049911e-01,  1.40790105e-01, -5.02257824e-01,\n",
       "        -7.01746166e-01, -3.44856352e-01,  6.66319802e-02,\n",
       "         3.93213719e-01, -8.84660602e-01,  9.30101573e-01,\n",
       "        -8.85131598e-01,  2.72719085e-01,  9.99498606e-01,\n",
       "         2.90236712e-01, -5.28612673e-01,  1.69663474e-01,\n",
       "        -2.71336049e-01, -3.26814651e-02,  1.65768668e-01,\n",
       "         3.03973705e-01, -8.79258633e-01, -1.27774954e-01,\n",
       "         3.87177393e-02,  1.84019223e-01, -9.77121666e-02,\n",
       "         1.31025180e-01,  4.52925295e-01,  8.60959291e-02,\n",
       "        -4.37960476e-01, -2.99244374e-01, -8.93172622e-03,\n",
       "         3.46996039e-01,  6.07983112e-01, -3.08107346e-01,\n",
       "        -4.45143431e-02,  1.94988087e-01,  1.03574574e-01,\n",
       "        -5.51916301e-01, -1.60497949e-01, -1.03100054e-01,\n",
       "        -9.68352437e-01,  1.54741257e-01, -9.99973953e-01,\n",
       "        -2.53270477e-01, -6.39926016e-01, -1.96589947e-01,\n",
       "         7.58427799e-01,  1.24526225e-01, -2.09959671e-01,\n",
       "        -4.68626291e-01,  4.54865664e-01,  7.69421518e-01,\n",
       "         5.03919601e-01, -1.67672083e-01,  1.08820349e-01,\n",
       "        -5.21844447e-01,  1.65406149e-02, -3.59249418e-03,\n",
       "         1.03756785e-01, -8.18114635e-03,  6.18739426e-01,\n",
       "        -1.02713794e-01,  9.99978006e-01, -5.53332195e-02,\n",
       "        -3.48007321e-01, -7.49147952e-01,  1.36028692e-01,\n",
       "        -2.98569411e-01,  9.97939765e-01, -5.36713541e-01,\n",
       "        -8.93109202e-01,  2.09684461e-01, -8.43198448e-02,\n",
       "        -5.81214905e-01,  1.89736634e-01, -1.77020263e-02,\n",
       "        -5.06938159e-01, -8.95640999e-02,  6.87185168e-01,\n",
       "         5.15995026e-01, -5.11235654e-01,  2.38706127e-01,\n",
       "        -2.59995818e-01, -2.46794224e-01,  4.56801169e-02,\n",
       "        -3.59841734e-01,  9.68422174e-01,  1.78429946e-01,\n",
       "         6.16744459e-01,  4.59201276e-01,  8.15222636e-02,\n",
       "         8.54609072e-01,  2.09414557e-01,  7.85572976e-02,\n",
       "         7.90545344e-02,  9.99730051e-01,  2.87101239e-01,\n",
       "        -8.79454136e-01,  1.17116451e-01, -9.14023578e-01,\n",
       "        -1.47290245e-01, -8.50924850e-01,  7.10823014e-02,\n",
       "         6.50506839e-02,  7.42053151e-01, -2.58119643e-01,\n",
       "         8.87076199e-01,  4.29913342e-01,  3.91646139e-02,\n",
       "         9.80918929e-02,  4.66340512e-01,  3.04327935e-01,\n",
       "        -7.34625995e-01, -9.66551006e-01, -9.71899509e-01,\n",
       "         3.12556654e-01, -3.90471965e-01,  5.99150881e-02,\n",
       "         3.38219076e-01,  6.15652613e-02,  2.30497465e-01,\n",
       "         2.82981783e-01, -9.99762416e-01,  8.15920889e-01,\n",
       "         2.42096975e-01, -3.92258704e-01,  9.35386598e-01,\n",
       "         2.50065446e-01,  2.33332500e-01,  2.47215986e-01,\n",
       "        -9.74635243e-01, -6.74140453e-01, -1.48017824e-01,\n",
       "        -3.11034232e-01,  6.25668943e-01,  5.17923653e-01,\n",
       "         6.28993034e-01,  2.20029473e-01, -4.44772929e-01,\n",
       "        -7.56534934e-02,  3.41355562e-01, -5.05447984e-01,\n",
       "        -9.82294142e-01,  2.69230545e-01,  3.66821140e-01,\n",
       "        -6.99815154e-01,  9.05743599e-01, -6.31234705e-01,\n",
       "        -9.90298390e-02,  6.30530000e-01,  3.58016849e-01,\n",
       "         5.73047042e-01,  5.59841275e-01,  1.53048754e-01,\n",
       "        -9.47745591e-02,  4.25114125e-01,  7.79061615e-01,\n",
       "         7.74366498e-01,  9.76330996e-01,  1.99815214e-01,\n",
       "         3.95348549e-01,  3.64234388e-01,  1.91063747e-01,\n",
       "         7.41359472e-01, -8.93315613e-01,  2.12013163e-03,\n",
       "        -2.43994206e-01, -3.67636904e-02,  1.72103032e-01,\n",
       "        -2.77593553e-01, -7.12142467e-01,  7.22907126e-01,\n",
       "        -1.94389492e-01,  3.46153289e-01, -2.57783800e-01,\n",
       "         1.85741097e-01, -4.15287226e-01, -1.51989147e-01,\n",
       "        -5.89565516e-01, -3.81730527e-01,  5.64693034e-01,\n",
       "        -7.80034810e-03,  8.06967795e-01, -7.90022537e-02,\n",
       "        -2.52307160e-03, -4.82926816e-01, -1.07178353e-01,\n",
       "         5.77900112e-01, -8.86988819e-01,  7.41209328e-01,\n",
       "         4.60736006e-02,  6.78384483e-01, -3.22597921e-01,\n",
       "        -2.31424809e-01,  8.09169829e-01, -4.90987718e-01,\n",
       "        -1.98879406e-01, -1.46297500e-01, -5.38407266e-01,\n",
       "         5.56085289e-01, -1.59689352e-01, -3.48930329e-01,\n",
       "        -3.99758637e-01,  4.51409787e-01,  3.02688688e-01,\n",
       "         9.57654297e-01,  4.12001312e-01,  2.32500181e-01,\n",
       "        -3.84138003e-02,  5.78394793e-02,  2.55394101e-01,\n",
       "        -2.29587778e-01, -9.99822497e-01,  3.12322885e-01,\n",
       "         2.93178022e-01, -2.55302429e-01, -1.55275941e-01,\n",
       "        -3.51371884e-01, -4.39247414e-02, -7.99672008e-01,\n",
       "        -1.89960226e-01, -5.14039993e-02,  6.45025149e-02,\n",
       "        -4.07846600e-01, -3.75633061e-01,  4.54796344e-01,\n",
       "         3.39927971e-01,  1.83263421e-01,  7.41485059e-01,\n",
       "         2.26136252e-01,  6.59485042e-01,  5.88312805e-01,\n",
       "         4.49877262e-01, -5.73842227e-01,  6.48613095e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b71e9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
       " array([[[ 0.13862704,  0.15826836, -0.2966649 , ..., -0.27084973,\n",
       "          -0.28436327,  0.45808414],\n",
       "         [ 0.53636336, -0.23269622,  0.17541951, ...,  0.55402565,\n",
       "           0.49807116, -0.00240759],\n",
       "         [ 0.30023715, -0.34751177,  0.12084441, ..., -0.45624903,\n",
       "           0.32880178,  0.87728167],\n",
       "         ...,\n",
       "         [ 0.37985945,  0.12028794,  0.82829225, ..., -0.86237276,\n",
       "          -0.59569633,  0.04711594],\n",
       "         [-0.02524202, -0.7176754 , -0.6950472 , ...,  0.07574195,\n",
       "          -0.66678166, -0.3400749 ],\n",
       "         [ 0.75353885,  0.23910885,  0.07174353, ...,  0.24671493,\n",
       "          -0.64580613, -0.32129788]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-0.9376786 , -0.5042589 , -0.979893  ,  0.9030439 ,  0.9329325 ,\n",
       "         -0.24377505,  0.8925754 ,  0.228806  , -0.9531208 , -0.99999535,\n",
       "         -0.8862303 ,  0.99055725,  0.9855201 ,  0.71552855,  0.9454762 ,\n",
       "         -0.86448497, -0.60352373, -0.6665585 ,  0.30200154, -0.15873313,\n",
       "          0.7455269 ,  1.        , -0.4021888 ,  0.42608014,  0.61509013,\n",
       "          0.99962306, -0.8773361 ,  0.95938957,  0.95852876,  0.69501513,\n",
       "         -0.67183834,  0.33250904, -0.995359  , -0.22675511, -0.9657978 ,\n",
       "         -0.99510974,  0.6127018 , -0.7669506 ,  0.0873445 ,  0.08236378,\n",
       "         -0.9518442 ,  0.47129756,  0.9999979 ,  0.3298952 ,  0.7583101 ,\n",
       "         -0.26704833, -1.        ,  0.31664473, -0.93642735,  0.9910324 ,\n",
       "          0.9719467 ,  0.9892896 ,  0.21901852,  0.60477006,  0.5848996 ,\n",
       "         -0.4122711 , -0.00629385,  0.17190644, -0.3987574 , -0.618993  ,\n",
       "         -0.6603152 ,  0.5068678 , -0.9756918 , -0.9039308 ,  0.9926243 ,\n",
       "          0.93226534, -0.36873212, -0.4869069 , -0.314323  ,  0.04989558,\n",
       "          0.91290236,  0.3396146 , -0.1879475 , -0.92346257,  0.86747605,\n",
       "          0.3227536 , -0.6406079 ,  1.        , -0.7988526 , -0.9930688 ,\n",
       "          0.962933  ,  0.91240627,  0.48271605, -0.7275582 ,  0.5996145 ,\n",
       "         -1.        ,  0.7548478 , -0.15997006, -0.994149  ,  0.33858255,\n",
       "          0.8394346 , -0.415774  ,  0.29430977,  0.61109614, -0.57447696,\n",
       "         -0.7184506 , -0.4768405 , -0.96814406, -0.4326704 , -0.67323315,\n",
       "          0.12483034, -0.20933421, -0.58818436, -0.41860685,  0.54470927,\n",
       "         -0.6125471 , -0.6138066 ,  0.4712145 ,  0.47791412,  0.7633289 ,\n",
       "          0.39740136, -0.41479257,  0.7063263 , -0.96801776,  0.7389451 ,\n",
       "         -0.4269571 , -0.9947576 , -0.6018672 , -0.99504566,  0.74590665,\n",
       "         -0.63428104, -0.27531794,  0.9522238 , -0.57242686,  0.62179524,\n",
       "         -0.12949048, -0.99051815, -1.        , -0.8709735 , -0.7506068 ,\n",
       "         -0.50083554, -0.48268545, -0.9871631 , -0.98470193,  0.7213619 ,\n",
       "          0.96944666,  0.301281  ,  0.99999064, -0.4426685 ,  0.9698506 ,\n",
       "         -0.5431185 , -0.81887203,  0.9180295 , -0.5131957 ,  0.9025567 ,\n",
       "          0.5273866 , -0.5939676 ,  0.29279983, -0.6932557 ,  0.7179124 ,\n",
       "         -0.9318366 , -0.27759176, -0.91604805, -0.9456746 , -0.32868883,\n",
       "          0.95555556, -0.79270726, -0.9860028 , -0.19044176, -0.27600545,\n",
       "         -0.6061537 ,  0.9005307 ,  0.9266373 ,  0.4352979 , -0.68583053,\n",
       "          0.4720402 ,  0.28506824,  0.7684514 , -0.8646656 , -0.56257737,\n",
       "          0.5126705 , -0.5468343 , -0.94900864, -0.9907118 , -0.5809063 ,\n",
       "          0.7146272 ,  0.9948339 ,  0.7980904 ,  0.3462593 ,  0.9348572 ,\n",
       "         -0.42384437,  0.9332701 , -0.9754466 ,  0.9935824 , -0.2596514 ,\n",
       "          0.4664672 , -0.53999895,  0.49472582, -0.8722778 ,  0.00338849,\n",
       "          0.83776444, -0.9134249 , -0.8431692 , -0.25158226, -0.51769024,\n",
       "         -0.46870977, -0.9490975 ,  0.5691279 , -0.48558095, -0.4856518 ,\n",
       "         -0.22445995,  0.96093917,  0.9822893 ,  0.7495633 ,  0.62555116,\n",
       "          0.8551897 , -0.9073241 , -0.58024305,  0.28742263,  0.30171227,\n",
       "          0.30159456,  0.9973753 , -0.8503049 , -0.21080606, -0.9260725 ,\n",
       "         -0.99070805, -0.02516756, -0.9488478 , -0.3971862 , -0.80972624,\n",
       "          0.87068224, -0.75122803,  0.8106708 ,  0.54876304, -0.9829863 ,\n",
       "         -0.85692126,  0.4852352 , -0.61555696,  0.48461312, -0.2893155 ,\n",
       "          0.9647096 ,  0.985797  , -0.70642924,  0.7120392 ,  0.959345  ,\n",
       "         -0.9589809 , -0.8707507 ,  0.7892768 , -0.35606387,  0.86029965,\n",
       "         -0.7242924 ,  0.98818654,  0.98757863,  0.9282262 , -0.9547475 ,\n",
       "         -0.83288914, -0.79934967, -0.83976924, -0.2332967 ,  0.23149182,\n",
       "          0.97116846,  0.6054525 ,  0.6388193 ,  0.24286805, -0.7883978 ,\n",
       "          0.99813014, -0.94476086, -0.9803666 , -0.81843853, -0.35336712,\n",
       "         -0.99509096,  0.9728791 ,  0.41646644,  0.8093689 , -0.6227092 ,\n",
       "         -0.81832784, -0.981674  ,  0.85319096,  0.12420875,  0.98260236,\n",
       "         -0.63760734, -0.94500613, -0.8093604 , -0.9747823 ,  0.04118007,\n",
       "         -0.30971003, -0.8153306 , -0.03058937, -0.9255172 ,  0.5676857 ,\n",
       "          0.6216603 ,  0.6651731 , -0.968216  ,  0.9997298 ,  1.        ,\n",
       "          0.9825576 ,  0.9013463 ,  0.8950181 , -0.9999986 , -0.80812514,\n",
       "          0.9999988 , -0.9995222 , -1.        , -0.9361452 , -0.82000804,\n",
       "          0.47551456, -1.        , -0.26976207, -0.01114206, -0.9296612 ,\n",
       "          0.84915453,  0.9879218 ,  0.9950281 , -1.        ,  0.86529595,\n",
       "          0.9512621 , -0.56789625,  0.9965562 , -0.6713038 ,  0.9814817 ,\n",
       "          0.6007991 ,  0.74141747, -0.326539  ,  0.55740994, -0.9800917 ,\n",
       "         -0.89560354, -0.80820966, -0.9266759 ,  0.9999365 ,  0.25422576,\n",
       "         -0.7969756 , -0.8854041 ,  0.7831084 , -0.1391365 , -0.00604201,\n",
       "         -0.978641  , -0.45034003,  0.88950574,  0.9020898 ,  0.3021423 ,\n",
       "          0.26503178, -0.5750338 ,  0.50986254,  0.12155094,  0.11701995,\n",
       "          0.6484098 , -0.9504878 , -0.38886145, -0.6937505 ,  0.2507666 ,\n",
       "         -0.75262475, -0.98310596,  0.9646208 , -0.27421296,  0.98648363,\n",
       "          1.        ,  0.37562203, -0.90451014,  0.88469744,  0.4860115 ,\n",
       "         -0.5514641 ,  1.        ,  0.9092157 , -0.99040484, -0.49585894,\n",
       "          0.79001313, -0.7155994 , -0.828025  ,  0.9998581 , -0.41974077,\n",
       "         -0.9281556 , -0.7732698 ,  0.9944566 , -0.99556184,  0.9997706 ,\n",
       "         -0.8985135 , -0.98384994,  0.97349924,  0.9654736 , -0.8102996 ,\n",
       "         -0.83253324,  0.1020261 , -0.672214  ,  0.4561355 , -0.9412212 ,\n",
       "          0.83958375,  0.69787663, -0.12014595,  0.92877555, -0.83450377,\n",
       "         -0.63121974,  0.43557176, -0.89007926, -0.45648628,  0.9873616 ,\n",
       "          0.5708537 , -0.2110518 , -0.02060676, -0.41823655, -0.9115844 ,\n",
       "         -0.9780631 ,  0.82459265,  1.        , -0.4228694 ,  0.9489127 ,\n",
       "         -0.52259123, -0.09856727,  0.22024465,  0.74591506,  0.7152115 ,\n",
       "         -0.35277775, -0.87997043,  0.9298512 , -0.9716049 , -0.99490005,\n",
       "          0.72775966,  0.22061637, -0.49437502,  1.        ,  0.6285    ,\n",
       "          0.3794799 ,  0.7227852 ,  0.9993162 ,  0.0300702 ,  0.59361863,\n",
       "          0.98155195,  0.9914458 , -0.34654403,  0.5882202 ,  0.8365395 ,\n",
       "         -0.98242056, -0.44884238, -0.76117057,  0.1331081 , -0.9479299 ,\n",
       "         -0.05588019, -0.96974975,  0.98457885,  0.9960217 ,  0.5818412 ,\n",
       "          0.31210375,  0.8577061 ,  1.        , -0.9273904 ,  0.66934896,\n",
       "         -0.13647193,  0.80350405, -0.9999917 , -0.8056512 , -0.4504487 ,\n",
       "         -0.17113797, -0.95122117, -0.5898851 ,  0.39912385, -0.9754495 ,\n",
       "          0.9563166 ,  0.8805611 , -0.9937362 , -0.99228024, -0.4979302 ,\n",
       "          0.88532573,  0.1439095 , -0.99939173, -0.89857906, -0.62722874,\n",
       "          0.8385112 , -0.32385337, -0.94701904, -0.70087886, -0.47676122,\n",
       "          0.5741789 , -0.2215695 ,  0.5664555 ,  0.9666835 ,  0.7934849 ,\n",
       "         -0.9401054 , -0.6745936 , -0.17533846, -0.9163417 ,  0.94093394,\n",
       "         -0.87010884, -0.9893605 , -0.25140837,  1.        , -0.40869698,\n",
       "          0.93852764,  0.6050118 ,  0.8218854 , -0.27122396,  0.3326212 ,\n",
       "          0.98272383,  0.36131933, -0.83142096, -0.9849705 , -0.28606427,\n",
       "         -0.53982073,  0.8254335 ,  0.8414235 ,  0.75901294,  0.94122875,\n",
       "          0.96271044,  0.2765099 , -0.07372506,  0.03992769,  0.9998474 ,\n",
       "         -0.30951768, -0.19327542, -0.46890172, -0.25110954, -0.4629131 ,\n",
       "         -0.29137444,  1.        ,  0.39625415,  0.7777107 , -0.9949602 ,\n",
       "         -0.98075765, -0.9302529 ,  1.        ,  0.88222426, -0.68483055,\n",
       "          0.81237364,  0.6241763 , -0.25508198,  0.82660097, -0.27906564,\n",
       "         -0.31672725,  0.22944526,  0.16818143,  0.9627001 , -0.67376876,\n",
       "         -0.99035686, -0.7910483 ,  0.7099378 , -0.97696674,  0.9999993 ,\n",
       "         -0.7029678 , -0.39604878, -0.5981427 , -0.6682929 , -0.27273464,\n",
       "         -0.01829566, -0.98817545, -0.38414803,  0.56053257,  0.97445387,\n",
       "          0.3504893 , -0.48977095, -0.9298339 ,  0.9578351 ,  0.953261  ,\n",
       "         -0.9858871 , -0.95974535,  0.9777033 , -0.9784289 ,  0.7550499 ,\n",
       "          1.        ,  0.3445877 ,  0.6786016 ,  0.39467093, -0.5348903 ,\n",
       "          0.5540542 , -0.6753829 ,  0.80778867, -0.9594635 , -0.44842356,\n",
       "         -0.3900548 ,  0.3983125 , -0.1319177 , -0.289593  ,  0.7860319 ,\n",
       "          0.34999263, -0.5530305 , -0.72944564, -0.23607792,  0.4663449 ,\n",
       "          0.93319285, -0.30481094, -0.19163495,  0.23183006, -0.32304814,\n",
       "         -0.9323409 , -0.4672354 , -0.6315389 , -1.        ,  0.8067945 ,\n",
       "         -1.        ,  0.8035263 ,  0.40656915, -0.36996433,  0.8760366 ,\n",
       "          0.782903  ,  0.8298427 , -0.86282486, -0.9794617 ,  0.13217978,\n",
       "          0.8529287 , -0.50289536, -0.90573984, -0.6917757 ,  0.50166076,\n",
       "         -0.20521945,  0.15640745, -0.7397342 ,  0.81556314, -0.34136412,\n",
       "          1.        ,  0.26589802, -0.829207  , -0.9821179 ,  0.24909708,\n",
       "         -0.30092302,  1.        , -0.89523506, -0.98315346,  0.33299097,\n",
       "         -0.91795   , -0.84932876,  0.586756  ,  0.16526465, -0.8522476 ,\n",
       "         -0.9960892 ,  0.9220455 ,  0.86608016, -0.6476966 ,  0.792742  ,\n",
       "         -0.39908424, -0.76908225,  0.15115355,  0.9868105 ,  0.9924343 ,\n",
       "          0.7316744 ,  0.90827537, -0.122649  , -0.5258375 ,  0.9840351 ,\n",
       "          0.40086427, -0.04361095,  0.13608694,  1.        ,  0.4003718 ,\n",
       "         -0.94971836, -0.13093911, -0.9787602 , -0.35216966, -0.95511305,\n",
       "          0.37547463,  0.3099394 ,  0.9194709 , -0.44600484,  0.973811  ,\n",
       "         -0.9713665 ,  0.1900938 , -0.8894485 , -0.7863345 ,  0.47566864,\n",
       "         -0.94627994, -0.989229  , -0.99379843,  0.8141796 , -0.40769172,\n",
       "         -0.18949994,  0.2102122 ,  0.17150044,  0.632215  ,  0.55656344,\n",
       "         -1.        ,  0.9642159 ,  0.61497796,  0.97675025,  0.97680116,\n",
       "          0.91147435,  0.81081504,  0.3250571 , -0.9919876 , -0.991035  ,\n",
       "         -0.5437975 , -0.35674727,  0.79595315,  0.76478744,  0.8900011 ,\n",
       "          0.6469603 , -0.4874782 , -0.47918567, -0.7755676 , -0.8422663 ,\n",
       "         -0.9971619 ,  0.5961326 , -0.8679444 , -0.967766  ,  0.97183466,\n",
       "         -0.3461099 , -0.15342884, -0.21388392, -0.95864207,  0.93210816,\n",
       "          0.7627043 ,  0.4636386 ,  0.08617783,  0.50709873,  0.91700137,\n",
       "          0.95966476,  0.98817444, -0.923057  ,  0.8554584 , -0.91963243,\n",
       "          0.6712206 ,  0.93809915, -0.9606301 ,  0.23346196,  0.8300922 ,\n",
       "         -0.55601096,  0.3696073 , -0.47518626, -0.974005  ,  0.8173753 ,\n",
       "         -0.4267749 ,  0.7772788 , -0.47978634,  0.06386205, -0.47184733,\n",
       "         -0.26067355, -0.7623679 , -0.8742259 ,  0.65762377,  0.6207219 ,\n",
       "          0.9219022 ,  0.9359767 , -0.04963619, -0.89422816, -0.37006137,\n",
       "         -0.8943973 , -0.9525815 ,  0.9536075 , -0.08509368, -0.29609844,\n",
       "          0.9030915 ,  0.13211587,  0.9323627 ,  0.42885384, -0.49890807,\n",
       "         -0.41743675, -0.76385844,  0.8886789 , -0.78942204, -0.76387584,\n",
       "         -0.7092896 ,  0.81046253,  0.35951063,  1.        , -0.91881144,\n",
       "         -0.98778635, -0.8268005 , -0.6011908 ,  0.49917865, -0.78802055,\n",
       "         -1.        ,  0.3609428 , -0.8313559 ,  0.8524061 , -0.9397852 ,\n",
       "          0.94995785, -0.9338528 , -0.9851252 , -0.34948185,  0.8436267 ,\n",
       "          0.93746185, -0.5158689 , -0.89891857,  0.5195579 , -0.87971115,\n",
       "          0.9979246 ,  0.87525606, -0.82766587, -0.00118596,  0.60126925,\n",
       "         -0.91844785, -0.73978645,  0.9227983 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1,2,3],\n",
    " [3,4,5,6],\n",
    " [7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb36289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.36.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: c:\\users\\rory\\anaconda3\\envs\\tf\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d27d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
